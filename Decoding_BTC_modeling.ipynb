{"cells":[{"cell_type":"markdown","metadata":{"id":"MJ-EMXYerkA7"},"source":["# Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfPC0RCkrkA-"},"outputs":[],"source":["import shap\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Embedding, Dense, concatenate, RepeatVector, Input, Bidirectional, RepeatVector, TimeDistributed, GRU\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import load_model\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.layers import GRU, Dense\n","from tensorflow.keras.layers import SimpleRNN, Dense\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n","\n","from tensorflow.keras.layers import GRU, Dense\n","from tensorflow.keras.layers import SimpleRNN, Dense\n","from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense\n","\n","\n","import numpy as np\n","import pandas as pd\n","\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMhblHZcrkBA"},"outputs":[],"source":["df_technical = pd.read_csv(\"Technical_indicators_final.csv\", index_col=0)\n","df_onchain_data = pd.read_csv(\"onchain_data_final.csv\", index_col=0)\n","df_sentiment_index = pd.read_csv(\"Sentiment_Index_final.csv\", index_col=0)\n","df_traditional_assets = pd.read_csv(\"traditional_assets_data_final.csv\", index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-JmHNdRrkBA"},"outputs":[],"source":["print(len(df_technical), len(df_onchain_data), len(df_sentiment_index), len(df_traditional_assets))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S93_iMvnrkBB"},"outputs":[],"source":["df_technical['Date'] = pd.to_datetime(df_technical['Date'])\n","df_onchain_data['Date'] = pd.to_datetime(df_onchain_data['Date'])\n","df_sentiment_index['Date'] = pd.to_datetime(df_sentiment_index['Date'])\n","df_traditional_assets['Date'] = pd.to_datetime(df_traditional_assets['Date'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrfZ1zJPrkBB"},"outputs":[],"source":["df_onchain_data['Number of unique addresses per day'] = df_onchain_data['Number of unique addresses per day'].interpolate(method='linear')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3seWL0MrkBB"},"outputs":[],"source":["import pandas as pd\n","\n","merged_df = df_technical.merge(df_onchain_data, on='Date', how='right')\n","merged_df = merged_df.merge(df_sentiment_index, on='Date', how='right')\n","merged_df = merged_df.merge(df_traditional_assets, on='Date', how='right')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUB4IDhirkBC"},"outputs":[],"source":["merged_df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qentqsr_rkBC"},"outputs":[],"source":["target = merged_df['Close'].values\n","dates = pd.to_datetime(merged_df['Date'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHdrkAL_rkBC"},"outputs":[],"source":["def minmax_scaler(data):\n","    min_val = data.min(axis=0)\n","    max_val = data.max(axis=0)\n","    scaled_data = (data - min_val) / (max_val - min_val)\n","    return np.array(scaled_data), min_val, max_val\n","\n","def minmax_inverse_transform(scaled_data, min_val, max_val):\n","    return scaled_data * (max_val - min_val) + min_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hppi9cnBrkBC"},"outputs":[],"source":["cols = list(merged_df)[1:]\n","data = merged_df[cols].astype(float)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_sPemEtrkBD"},"outputs":[],"source":["def minmax_scaler(data):\n","    min_val = data.min(axis=0)\n","    max_val = data.max(axis=0)\n","    scaled_data = (data - min_val) / (max_val - min_val)\n","    return np.array(scaled_data), min_val, max_val\n","\n","def minmax_inverse_transform(scaled_data, min_val, max_val):\n","    return scaled_data * (max_val - min_val) + min_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4_nJkCErkBD"},"outputs":[],"source":["data_scaled, min_val, max_val = minmax_scaler(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uub-TfznrkBD"},"outputs":[],"source":["# split to train data and test data\n","n_train = int(0.8*data_scaled.shape[0])\n","train_data_scaled = data_scaled[0: n_train]\n","train_dates = dates[0: n_train]\n","\n","test_data_scaled = data_scaled[n_train:]\n","test_dates = dates[n_train:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gq7WpDg3rkBD"},"outputs":[],"source":["train_data_scaled.shape, test_data_scaled.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ed9-92y2rkBD"},"outputs":[],"source":["def reformat_data_for_LSTM(train_data_scaled, test_data_scaled, seq_len, pred_days):\n","    trainX = []\n","    trainY = []\n","    testX = []\n","    testY = []\n","    n_train = len(train_data_scaled)\n","\n","    for i in range(seq_len, n_train - pred_days + 1):\n","        trainX.append(train_data_scaled[i - seq_len:i, 0:train_data_scaled.shape[1]])\n","        trainY.append(train_data_scaled[i + pred_days - 1:i + pred_days, 0])\n","\n","    for i in range(seq_len, len(test_data_scaled) - pred_days + 1):\n","        testX.append(test_data_scaled[i - seq_len:i, 0:test_data_scaled.shape[1]])\n","        testY.append(test_data_scaled[i + pred_days - 1:i + pred_days, 0])\n","\n","    trainX, trainY = np.array(trainX), np.array(trainY)\n","    testX, testY = np.array(testX), np.array(testY)\n","\n","    return trainX, trainY, testX, testY\n","\n","trainX_3, trainY_3, testX_3, testY_3 = reformat_data_for_LSTM(train_data_scaled, test_data_scaled, 3, 1)\n","trainX_5, trainY_5, testX_5, testY_5 = reformat_data_for_LSTM(train_data_scaled, test_data_scaled, 5, 1)\n","trainX_14, trainY_14, testX_14, testY_14 = reformat_data_for_LSTM(train_data_scaled, test_data_scaled, 14, 1)\n","trainX_30, trainY_30, testX_30, testY_30 = reformat_data_for_LSTM(train_data_scaled, test_data_scaled, 30, 1)\n","trainX_60, trainY_60, testX_60, testY_60 = reformat_data_for_LSTM(train_data_scaled, test_data_scaled, 60, 1)\n","trainX_120, trainY_120, testX_120, testY_120 = reformat_data_for_LSTM(train_data_scaled, test_data_scaled, 120, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PwXcvcL1rkBD"},"outputs":[],"source":["learning_rate=0.005 # 0.01, 0.05, 0.0001, 0.0005\n","BATCH_SIZE = 64 # 64, 32, 16, 8\n","\n","def create_Bi_LSTM_model(input_shape, output_shape, optimizer='adam'):\n","    model = Sequential()\n","    model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape))\n","    model.add(Bidirectional(LSTM(32, return_sequences=False)))\n","    model.add(Dense(output_shape))\n","    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n","    return model\n","\n","def create_LSTM_model(input_shape, output_shape, optimizer='adam'):\n","    model = Sequential()\n","    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n","    model.add(LSTM(64, return_sequences=False))\n","    model.add(Dense(output_shape))\n","    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n","    return model\n","\n","def create_CNN_model(input_shape, output_shape):\n","    model = Sequential()\n","    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))\n","    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n","    model.add(GlobalMaxPooling1D())\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(output_shape))\n","    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n","    return model\n","\n","def create_GRU_model(input_shape, output_shape):\n","    model = Sequential()\n","    model.add(GRU(128, return_sequences=True, input_shape=input_shape))\n","    model.add(GRU(64, return_sequences=False))\n","    model.add(Dense(output_shape))\n","    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n","    return model\n","\n","def create_RNN_model(input_shape, output_shape):\n","    model = Sequential()\n","    model.add(SimpleRNN(128, return_sequences=True, input_shape=input_shape))\n","    model.add(SimpleRNN(64, return_sequences=False))\n","    model.add(Dense(output_shape))\n","    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n","    return model\n","\n","def MAPE(y_test, y_pred):\n","\treturn np.mean(np.abs((y_test - y_pred) / y_test)) * 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSTH55ZxrkBE"},"outputs":[],"source":["input_shape = (trainX_3.shape[1], trainX_3.shape[2])\n","output_shape = trainY_3.shape[1]\n","\n","lstm_model_3 = create_LSTM_model(input_shape, output_shape)\n","# Fit the model\n","history = lstm_model_3.fit(trainX_3, trainY_3, epochs=10, batch_size=BATCH_SIZE,\n","                verbose=0)\n","prediction_3_lstm = lstm_model_3.predict(testX_3)\n","\n","gru_model_3 = create_GRU_model(input_shape, output_shape)\n","# Fit the model\n","history = gru_model_3.fit(trainX_3, trainY_3, epochs=10, batch_size=BATCH_SIZE,\n","                verbose=0)\n","prediction_3_gru = gru_model_3.predict(testX_3)\n","\n","bi_lstm_model_3 = create_Bi_LSTM_model(input_shape, output_shape)\n","# Fit the model\n","history = bi_lstm_model_3.fit(trainX_3, trainY_3, epochs=10, batch_size=BATCH_SIZE,\n","                verbose=0)\n","prediction_3_bi_lstm = bi_lstm_model_3.predict(testX_3)\n","\n","cnn_model_3 = create_CNN_model(input_shape, output_shape)\n","# Fit the model\n","history = cnn_model_3.fit(trainX_3, trainY_3, epochs=10, batch_size=BATCH_SIZE,\n","                verbose=0)\n","prediction_3_cnn = cnn_model_3.predict(testX_3)\n","\n","rnn_model_3 = create_RNN_model(input_shape, output_shape)\n","# Fit the model\n","history = rnn_model_3.fit(trainX_3, trainY_3, epochs=10, batch_size=BATCH_SIZE,\n","                verbose=0)\n","prediction_3_rnn = rnn_model_3.predict(testX_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pjwoqg-6rkBE"},"outputs":[],"source":["rnn_model_3 = create_RNN_model(input_shape, output_shape)\n","# Fit the model\n","history = rnn_model_3.fit(trainX_3, trainY_3, epochs=10, batch_size=BATCH_SIZE,\n","                verbose=0)\n","prediction_3_rnn = rnn_model_3.predict(testX_3)\n","mape_rnn = MAPE(testY_3, prediction_3_rnn)\n","print(mape_rnn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qUFmOgNurkBE"},"outputs":[],"source":["gru_model_3 = create_GRU_model(input_shape, output_shape)\n","# Fit the model\n","history = gru_model_3.fit(trainX_3, trainY_3, epochs=10, batch_size=BATCH_SIZE,\n","                verbose=0)\n","prediction_3_gru = gru_model_3.predict(testX_3)\n","mape_gru = MAPE(testY_3, prediction_3_gru)\n","print(mape_gru)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8K2-5d1rkBE"},"outputs":[],"source":["cnn_model_3 = create_CNN_model(input_shape, output_shape)\n","# Fit the model\n","history = cnn_model_3.fit(trainX_3, trainY_3, epochs=10, batch_size=BATCH_SIZE,\n","                verbose=0)\n","prediction_3_cnn = cnn_model_3.predict(testX_3)\n","mape_cnn = MAPE(testY_3, prediction_3_cnn)\n","print(mape_cnn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfEpOxzOrkBE"},"outputs":[],"source":["# prediction_3_lstm = lstm_model_3.predict(testX_3)\n","# prediction_3_gru = gru_model_3.predict(testX_3)\n","# prediction_3_bi_lstm = bi_lstm_model_3.predict(testX_3)\n","# prediction_3_cnn = cnn_model_3.predict(testX_3)\n","# prediction_3_rnn = rnn_model_3.predict(testX_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0-eU52cOrkBE"},"outputs":[],"source":["prediction_3_lstm_rev = minmax_inverse_transform(prediction_3_lstm, min_val[0], max_val[0])\n","prediction_3_gru_rev = minmax_inverse_transform(prediction_3_gru, min_val[0], max_val[0])\n","prediction_3_cnn_rev = minmax_inverse_transform(prediction_3_cnn, min_val[0], max_val[0])\n","prediction_3_bi_lstm_rev = minmax_inverse_transform(prediction_3_bi_lstm, min_val[0], max_val[0])\n","prediction_3_rnn_rev = minmax_inverse_transform(prediction_3_rnn, min_val[0], max_val[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WSyf5cM5rkBE"},"outputs":[],"source":["plt.figure(figsize=(20, 10))\n","plt.xlabel('Date', fontsize=14)  # X축 레이블에 대한 글꼴 크기 설정\n","plt.ylabel('Bitcoin price(USD)', fontsize=14)  # Y축 레이블에 대한 글꼴 크기 설정\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","plt.plot(test_dates[120:], target[-294:], color='black', linestyle='--', label='Actual Close Price')\n","plt.plot(test_dates[120:], prediction_3_bi_lstm_rev[-294:], color='red', label='Bi LSTM')\n","plt.plot(test_dates[120:], prediction_3_lstm_rev[-294:], color='blue', label='LSTM')\n","plt.plot(test_dates[120:], prediction_3_cnn_rev[-294:], color='green', label='CNN')\n","plt.plot(test_dates[120:], prediction_3_gru_rev[-294:], color='cyan', label='GRU')\n","plt.plot(test_dates[120:], prediction_3_rnn_rev[-294:], color='magenta', label='RNN')\n","\n","plt.legend(fontsize=14)\n","\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}